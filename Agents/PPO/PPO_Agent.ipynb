{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Studienarbeit_GitHub\\Studienarbeit\\Agents\\PPO\n",
      "Notebook ausgeführt\n"
     ]
    }
   ],
   "source": [
    "%run ../../Environment/environment.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import random\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Seed setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 42\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "SEED  = seed % (2**32 - 1)\n",
    "print(f\"SEED: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Daten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten erfolgreich eingelesen\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# CSV Datem einlesen\n",
    "# -------------------------------\n",
    "train_data = pd.read_csv(\"../../Transform_data/stand_data/2023-2018_stand_data.csv\")\n",
    "train_data.drop('datetime', axis=1, inplace=True)\n",
    "\n",
    "test_data = pd.read_csv(\"../../Transform_data/stand_data/2025-2024_stand_data.csv\")\n",
    "test_data.drop('datetime', axis=1, inplace=True)\n",
    "\n",
    "if(train_data is not None and test_data is not None):\n",
    "    print(\"Daten erfolgreich eingelesen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Parallele Umgebungen erstellen für das Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "def make_env():\n",
    "    return TradingEnv(\n",
    "        data=train_data,\n",
    "        initial_cash=10_000,\n",
    "        window_size=336,\n",
    "        scaler_path=\"../../Transform_data/scaler.pkl\",\n",
    "        default_seed=SEED\n",
    "    )\n",
    "\n",
    "n_envs = 8  # Mehr parallele Umgebungen (8, 16 oder sogar 32 testen!)\n",
    "env = SubprocVecEnv([make_env for _ in range(n_envs)])\n",
    "\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
    "env.training = True  # Sicherstellen, dass Normalisierung aktiv ist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Erstellen des Agenten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tlfin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch import nn  # Für die Netzwerkarchitektur\n",
    "\n",
    "# Definiere das neuronale Netz\n",
    "policy_kwargs = dict(\n",
    "    net_arch=[dict(pi=[128, 128], vf=[128, 128])],  # Zwei Layer mit 128 Neuronen\n",
    "    activation_fn=nn.ReLU,  # Verwende ReLU als Aktivierungsfunktion\n",
    ")\n",
    "\n",
    "# Erstelle den PPO-Agenten mit verbesserten Einstellungen\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate=0.0001,  # Lernrate\n",
    "    gamma=0.99,  # Discount-Faktor\n",
    "    clip_range=0.2,  # PPO-Clip-Parameter\n",
    "    ent_coef=0.01,  # Entropie-Koeffizient\n",
    "    n_steps=4_096,  # WICHTIG: Mehr Schritte pro Update → GPU-Auslastung steigt\n",
    "    batch_size=4_096,  # WICHTIG: Große Batch-Größe → GPU rechnet effizienter\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=1,\n",
    "    seed=SEED,\n",
    "    device=\"cuda\",  # Nutzt die GPU!\n",
    "    #tensorboard_log=\"./tensorboard_log/\"  # Optional: Logging für TensorBoard\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modell trainieren und speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1288   |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 203    |\n",
      "|    total_timesteps | 262144 |\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "model.save(\"ppo_trading_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
