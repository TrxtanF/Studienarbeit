{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Environment/environment.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Seed setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "SEED  = seed % (2**32 - 1)\n",
    "print(f\"SEED: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Daten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# CSV Datem einlesen\n",
    "# -------------------------------\n",
    "train_data = pd.read_csv(\"../../Transform_data/stand_data/2023-2018_stand_data.csv\")\n",
    "train_data.drop('datetime', axis=1, inplace=True)\n",
    "\n",
    "test_data = pd.read_csv(\"../../Transform_data/stand_data/2025-2024_stand_data.csv\")\n",
    "test_data.drop('datetime', axis=1, inplace=True)\n",
    "\n",
    "if(train_data is not None and test_data is not None):\n",
    "    print(\"Daten erfolgreich eingelesen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. RL Modell laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A2C_model = PPO.load(\"A2C/a2c_trading_model.zip\")\n",
    "#DQN_model = PPO.load(\"DQN/dqn_trading_model.zip\")\n",
    "PPO_model = PPO.load(\"PPO/ppo_trading_model.zip\")\n",
    "\n",
    "model = PPO_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Umgebungen erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = TradingEnv(\n",
    "        data=train_data,\n",
    "        initial_cash=10_000,\n",
    "        window_size=336,\n",
    "        scaler_path=\"../../Transform_data/scaler.pkl\",\n",
    "        default_seed=SEED\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = TradingEnv(\n",
    "        data=train_data,\n",
    "        initial_cash=10_000,\n",
    "        window_size=336,\n",
    "        scaler_path=\"../../Transform_data/scaler.pkl\",\n",
    "        default_seed=SEED\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Performance auf gesehenen Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = train_env.reset(seed=SEED)\n",
    "done = False\n",
    "\n",
    "# Liste der actionen\n",
    "action_list = []\n",
    "\n",
    "while not done:\n",
    "    # Bestimme die Aktion (deterministisch)\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    action = int(action)  # oder: action = action.item()\n",
    "    obs, reward, done, truncated, info = train_env.step(action)\n",
    "    action_list.append(action)\n",
    "\n",
    "# Hier wird der Zustand gerendert (z.B. als Plot). Du kannst den Render-Modus anpassen.\n",
    "train_env.render(mode='human')\n",
    "print(action_list[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Performance auf ungesehenen Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = test_env.reset(seed=SEED)\n",
    "done = False\n",
    "\n",
    "# Liste der actionen\n",
    "action_list = []\n",
    "\n",
    "while not done:\n",
    "    # Bestimme die Aktion (deterministisch)\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    action = int(action)  # oder: action = action.item()\n",
    "    obs, reward, done, truncated, info = test_env.step(action)\n",
    "    action_list.append(action)\n",
    "\n",
    "# Hier wird der Zustand gerendert (z.B. als Plot). Du kannst den Render-Modus anpassen.\n",
    "test_env.render(mode='human')\n",
    "print(action_list[:200])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
