{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f99b6d0-8534-4d01-baaa-8559c9d9a58b",
   "metadata": {},
   "source": [
    "# Steps to train a Linear Regression Model\n",
    "\n",
    "1. Choose Dataset and fill <span style=\"color:blue\">x_train</span> & <span style=\"color:blue\">y_train</span> accordingly\n",
    "2. Adjust <span style=\"color:blue\">iterations</span> and <span style=\"color:blue\">tmp_aplha</span> (learning rate) as needed.\n",
    "3. Run the gradient descent function to get the optimal parameters.\n",
    "4. Use the final w and b to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea3b18d5-5211-402f-8ef3-30564832e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b):\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e302a7-1e30-4a01-9664-a9b1df47e379",
   "metadata": {},
   "source": [
    "5. Visualize results using matplotlib as shown in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1c8564-721f-4e2a-8031-1cde96881d39",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff1e7590-da05-4b6e-a4fb-06b9614827f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# House sizes in thousands of square feet (1000-3000 sq ft)\n",
    "x_train = np.array([1.0, 1.5, 2.0, 2.5, 3.0])\n",
    "\n",
    "# House prices in thousands of dollars\n",
    "# Each 500 sqft increase adds $100k to the price, starting at $200k for 1000 sqft\n",
    "y_train = np.array([200.0, 300.0, 400.0, 500.0, 600.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aba63c-7f37-4345-90f9-e220410e1908",
   "metadata": {},
   "source": [
    "This code loads the necessary libraries and sets up a simple dataset with two points: houses with 1000 and 2000 square feet, sold for 300,000€ and 500,000€ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05638220-a3b5-4ecb-9658-bf1bab33681f",
   "metadata": {},
   "source": [
    "# 2. Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5237b8f0-ddca-4eca-a264-a6f53778ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the cost\n",
    "def compute_cost(x, y, w, b):\n",
    "   \n",
    "    m = x.shape[0] \n",
    "    cost = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        cost = cost + (f_wb - y[i])**2\n",
    "    total_cost = 1 / (2 * m) * cost\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1419953-e0cb-45e1-bba6-a917f0293847",
   "metadata": {},
   "source": [
    "This function calculates the cost (error) of the current model parameters (w and b) given the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054ff7b-0969-46e3-b7b2-76fec90ed234",
   "metadata": {},
   "source": [
    "# 3. Gradient Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a8d4286-951f-40a4-b5b7-cf8e168f1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "      x (ndarray (m,)): Data, m examples \n",
    "      y (ndarray (m,)): target values\n",
    "      w,b (scalar)    : model parameters  \n",
    "    Returns\n",
    "      dj_dw (scalar): The gradient of the cost w.r.t. the parameters w\n",
    "      dj_db (scalar): The gradient of the cost w.r.t. the parameter b     \n",
    "     \"\"\"\n",
    "    \n",
    "    # Number of training examples\n",
    "    m = x.shape[0]    \n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range(m):  \n",
    "        f_wb = w * x[i] + b \n",
    "        dj_dw_i = (f_wb - y[i]) * x[i] \n",
    "        dj_db_i = f_wb - y[i] \n",
    "        dj_db += dj_db_i\n",
    "        dj_dw += dj_dw_i \n",
    "    dj_dw = dj_dw / m \n",
    "    dj_db = dj_db / m \n",
    "        \n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f16755-412f-43b6-a1a7-d9240ea2b2c4",
   "metadata": {},
   "source": [
    "This function computes the gradients of the cost function with respect to w and b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36480abb-9957-43e9-ba3c-781f9f76fb0d",
   "metadata": {},
   "source": [
    "# 4. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91a8a085-eac5-4b78-8431-522b8b2517ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in, alpha, num_iters): \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    p_history = []\n",
    "    b = b_in\n",
    "    w = w_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_dw, dj_db = compute_gradient(x, y, w, b)     \n",
    "        \n",
    "        # Update Parameters\n",
    "        b = b - alpha * dj_db                            \n",
    "        w = w - alpha * dj_dw                            \n",
    "        \n",
    "        # Save cost J at each iteration\n",
    "        if i < 100000:      # prevent resource exhaustion \n",
    "            J_history.append(compute_cost(x, y, w, b))\n",
    "            p_history.append([w,b])\n",
    "            \n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i % math.ceil(num_iters/10) == 0:\n",
    "            print(f\"Iteration {i:4}: Cost {J_history[-1]:0.2e} \",\n",
    "                  f\"dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db: 0.3e}  \",\n",
    "                  f\"w: {w: 0.3e}, b:{b: 0.5e}\")\n",
    " \n",
    "    return w, b, J_history, p_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff26c7-d11f-4e26-a1f3-c83ff417e6de",
   "metadata": {},
   "source": [
    "This function performs the gradient descent algorithm to optimize w and b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d6d43-28ae-47c0-8e89-76892364aedb",
   "metadata": {},
   "source": [
    "# 5. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43b738e3-0953-408d-abf7-840be89cc8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 8.06e+04  dj_dw: -9.000e+02, dj_db: -4.000e+02   w:  9.000e+00, b: 4.00000e+00\n",
      "Iteration 1000: Cost 4.96e+01  dj_dw: -1.252e+00, dj_db:  2.759e+00   w:  1.865e+02, b: 2.98126e+01\n",
      "Iteration 2000: Cost 7.79e+00  dj_dw: -4.964e-01, dj_db:  1.094e+00   w:  1.946e+02, b: 1.18209e+01\n",
      "Iteration 3000: Cost 1.22e+00  dj_dw: -1.968e-01, dj_db:  4.338e-01   w:  1.979e+02, b: 4.68705e+00\n",
      "Iteration 4000: Cost 1.93e-01  dj_dw: -7.805e-02, dj_db:  1.720e-01   w:  1.992e+02, b: 1.85844e+00\n",
      "Iteration 5000: Cost 3.03e-02  dj_dw: -3.095e-02, dj_db:  6.820e-02   w:  1.997e+02, b: 7.36885e-01\n",
      "Iteration 6000: Cost 4.76e-03  dj_dw: -1.227e-02, dj_db:  2.704e-02   w:  1.999e+02, b: 2.92180e-01\n",
      "Iteration 7000: Cost 7.48e-04  dj_dw: -4.865e-03, dj_db:  1.072e-02   w:  1.999e+02, b: 1.15851e-01\n",
      "Iteration 8000: Cost 1.18e-04  dj_dw: -1.929e-03, dj_db:  4.251e-03   w:  2.000e+02, b: 4.59357e-02\n",
      "Iteration 9000: Cost 1.85e-05  dj_dw: -7.649e-04, dj_db:  1.686e-03   w:  2.000e+02, b: 1.82138e-02\n",
      "\n",
      "(w,b) found by gradient descent: (199.9967,  0.0072)\n"
     ]
    }
   ],
   "source": [
    "w_init = 0\n",
    "b_init = 0\n",
    "iterations = 10000\n",
    "tmp_alpha = 0.01\n",
    "\n",
    "w_final, b_final, J_hist, p_hist = gradient_descent(x_train, y_train, w_init, b_init, tmp_alpha, iterations)\n",
    "print(f\"\\n(w,b) found by gradient descent: ({w_final:8.4f},{b_final:8.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2f92f3-717b-4005-8b48-73d54fcf5a4e",
   "metadata": {},
   "source": [
    "With w and b found, we can now predict values for the Model we trained with following equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fbfa62c6-17b7-4ea4-897e-157bf9e0137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b):\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d8d72-8abd-4636-bd09-f08a275c431c",
   "metadata": {},
   "source": [
    "The function predict will return a value y for the entered x data as a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a2c82517-74ab-4b31-86ce-44598cd6861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_to_predict = 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "601bca37-07db-481e-8a56-96048624913c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360.00132439802763"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(value_to_predict,w_final,b_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f580fa1-1d84-4729-a728-9ae25ed1885e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476dc162-5365-41b0-aca4-2c14b5ca9437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
