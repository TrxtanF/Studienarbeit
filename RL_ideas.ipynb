{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation und Einrichtung\n",
    "Bevor du startest, stelle sicher, dass du die folgenden Pakete installiert hast. Führe in einer Jupyter-Notebook-Zelle Folgendes aus:\n",
    "\n",
    "``pip install stable-baselines3 pandas matplotlib``\n",
    "\n",
    "stable-baselines3: Für Reinforcement Learning.\n",
    "pandas: Für die Datenverarbeitung.\n",
    "matplotlib: Für die grafische Darstellung.\n",
    "ccxt: Für die API-Anbindung an Kryptobörsen wie Binance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Datenimport und Vorbereitung\n",
    "In dieser Zelle holen wir die historischen Bitcoin-Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "def fetch_bitcoin_data(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Ruft Bitcoin-Daten von Yahoo Finance für den angegebenen Zeitraum ab.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): Startdatum im Format 'YYYY-MM-DD'.\n",
    "        end_date (str): Enddatum im Format 'YYYY-MM-DD'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame mit den historischen Kursdaten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Überprüfung der Datumsformate\n",
    "        pd.to_datetime(start_date)\n",
    "        pd.to_datetime(end_date)\n",
    "\n",
    "        # Sicherstellen, dass start_date vor end_date liegt\n",
    "        if start_date >= end_date:\n",
    "            raise ValueError(\"Das Startdatum muss vor dem Enddatum liegen.\")\n",
    "\n",
    "        # Lade Daten von Yahoo Finance\n",
    "        df = yf.download(\"BTC-USD\", start=start_date, end=end_date, interval=\"1d\")\n",
    "\n",
    "        # Überprüfen, ob Daten zurückgegeben wurden\n",
    "        if df.empty:\n",
    "            raise ValueError(\"Keine Daten für den angegebenen Zeitraum verfügbar.\")\n",
    "\n",
    "        # Umbenennen der Spalten für Konsistenz\n",
    "        df.rename(columns={\n",
    "            \"Open\": \"open\",\n",
    "            \"High\": \"high\",\n",
    "            \"Low\": \"low\",\n",
    "            \"Close\": \"close\",\n",
    "            \"Volume\": \"volume\"\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Filtere die relevanten Spalten und setze den Zeitstempel als Index\n",
    "        df = df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "        df.index.name = \"timestamp\"\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Abrufen der Daten: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price               open          high           low         close  \\\n",
      "Ticker           BTC-USD       BTC-USD       BTC-USD       BTC-USD   \n",
      "timestamp                                                            \n",
      "2018-01-01  14112.200195  14112.200195  13154.700195  13657.200195   \n",
      "2018-01-02  13625.000000  15444.599609  13163.599609  14982.099609   \n",
      "2018-01-03  14978.200195  15572.799805  14844.500000  15201.000000   \n",
      "2018-01-04  15270.700195  15739.700195  14522.200195  15599.200195   \n",
      "2018-01-05  15477.200195  17705.199219  15202.799805  17429.500000   \n",
      "\n",
      "Price            volume  \n",
      "Ticker          BTC-USD  \n",
      "timestamp                \n",
      "2018-01-01  10291200000  \n",
      "2018-01-02  16846600192  \n",
      "2018-01-03  16871900160  \n",
      "2018-01-04  21783199744  \n",
      "2018-01-05  23840899072  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Abrufen der Daten\n",
    "data = fetch_bitcoin_data('2018-01-01', '2023-12-01')\n",
    "print(data.head())  # Zeige die ersten Zeilen der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **fetch_ohlcv**: Ruft Open, High, Low, Close, Volume (OHLCV) Daten ab.\n",
    "- **timestamp**: Zeitstempel für jeden Tag.\n",
    "- **close**: Schlusskurs, der für das Training verwendet wird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umgebung und Agent erstellen\n",
    "Hier definieren wir die RL-Umgebung und den Agenten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitcoinTradingEnv(gym.Env):\n",
    "    def __init__(self, data, window_size=30):\n",
    "        super(BitcoinTradingEnv, self).__init__()\n",
    "        self.data = data[['open', 'high', 'low', 'close', 'volume', 'sma_10', 'sma_30', 'ema_10', 'ema_30']].values\n",
    "        self.window_size = window_size\n",
    "        self.current_step = window_size\n",
    "\n",
    "        # Action Space: Kaufen, Verkaufen, Halten\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "\n",
    "        # Observation Space: Fenstergröße x Feature-Anzahl\n",
    "        n_features = self.data.shape[1]\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0, high=1, shape=(window_size, n_features), dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = self.window_size\n",
    "        return self._get_observation()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        Gibt ein Fenster der letzten `window_size` Tage für alle Features zurück.\n",
    "        \"\"\"\n",
    "        window = self.data[self.current_step - self.window_size:self.current_step]\n",
    "        normalized_window = (window - np.min(self.data, axis=0)) / (\n",
    "            np.max(self.data, axis=0) - np.min(self.data, axis=0)\n",
    "        )\n",
    "        return normalized_window\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Führt eine Aktion aus und berechnet die Belohnung.\n",
    "        \"\"\"\n",
    "        reward = 0  # Default-Belohnung\n",
    "\n",
    "        # Abbruchbedingung bei Überschreiten der Datenlänge\n",
    "        if self.current_step >= len(self.data) - 2:\n",
    "            done = True\n",
    "            return self._get_observation(), reward, done, {}\n",
    "\n",
    "        price_now = self.data[self.current_step, 3]  # Schließen-Preis heute\n",
    "        price_next = self.data[self.current_step + 1, 3]  # Schließen-Preis morgen\n",
    "\n",
    "        # Aktion auswerten\n",
    "        if action == 1:  # Kaufen\n",
    "            reward = (price_next - price_now) - 0.001 * price_now  # Handelskosten\n",
    "        elif action == 2:  # Verkaufen\n",
    "            reward = (price_now - price_next) - 0.001 * price_now  # Handelskosten\n",
    "        elif action == 0:  # Halten\n",
    "            reward = -0.01  # Minimaler Verlust für Inaktivität\n",
    "\n",
    "        # Nächster Schritt\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beobachtung nach Reset: (1, 60, 9)\n"
     ]
    }
   ],
   "source": [
    "# Teste die Beobachtung\n",
    "obs = env.reset()\n",
    "print(\"Beobachtung nach Reset:\", obs.shape)  # Sollte (1, 60) sein, da `DummyVecEnv` die Dimension erweitert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(data):\n",
    "    \"\"\"\n",
    "    Fügt technische Indikatoren wie gleitende Durchschnitte dem DataFrame hinzu.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Historische Kursdaten.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame mit zusätzlichen Indikatoren.\n",
    "    \"\"\"\n",
    "    data['sma_10'] = data['close'].rolling(window=10).mean()\n",
    "    data['sma_30'] = data['close'].rolling(window=30).mean()\n",
    "    data['ema_10'] = data['close'].ewm(span=10, adjust=False).mean()\n",
    "    data['ema_30'] = data['close'].ewm(span=30, adjust=False).mean()\n",
    "    \n",
    "    # Entferne NaN-Werte, die durch gleitende Fenster entstehen\n",
    "    data = data.dropna()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training und Modell speichern\n",
    "Führe diesen Code aus, um das Modell zu trainieren und zu speichern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_trading_model(model, env, n_eval_episodes=10):\n",
    "    \"\"\"\n",
    "    Evaluiert die Leistung des Modells über eine bestimmte Anzahl von Episoden.\n",
    "\n",
    "    Args:\n",
    "        model: Das trainierte RL-Modell.\n",
    "        env: Die Handelsumgebung.\n",
    "        n_eval_episodes (int): Anzahl der Episoden zur Evaluierung.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Durchschnittliche Belohnung und Standardabweichung.\n",
    "    \"\"\"\n",
    "    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=n_eval_episodes, deterministic=True)\n",
    "    print(f\"Durchschnittliche Belohnung: {mean_reward} ± {std_reward}\")\n",
    "    return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modell erfolgreich geladen. Training wird fortgesetzt.\n",
      "Logging to ./bitcoin_trading_logs/PPO_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\tlfin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1196   |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 1      |\n",
      "|    total_timesteps | 155648 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 842         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.82447e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.656      |\n",
      "|    explained_variance   | 0.0260396   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+06    |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -3.68e-05   |\n",
      "|    value_loss           | 1.2e+06     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 765          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.082368e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.651       |\n",
      "|    explained_variance   | 0.04468161   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.17e+05     |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -9.71e-05    |\n",
      "|    value_loss           | 8.6e+05      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 733           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 11            |\n",
      "|    total_timesteps      | 161792        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.0592104e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.654        |\n",
      "|    explained_variance   | 0.05346024    |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.88e+05      |\n",
      "|    n_updates            | 780           |\n",
      "|    policy_gradient_loss | -0.000374     |\n",
      "|    value_loss           | 6.6e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 722           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 163840        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.8071775e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.657        |\n",
      "|    explained_variance   | -0.0011117458 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.62e+05      |\n",
      "|    n_updates            | 790           |\n",
      "|    policy_gradient_loss | -0.000116     |\n",
      "|    value_loss           | 8.07e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 704          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.582643e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.657       |\n",
      "|    explained_variance   | 0.00444597   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.69e+05     |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -8.48e-05    |\n",
      "|    value_loss           | 6.92e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 694           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 167936        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017571391 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.651        |\n",
      "|    explained_variance   | 0.057964623   |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.77e+05      |\n",
      "|    n_updates            | 810           |\n",
      "|    policy_gradient_loss | 8.61e-07      |\n",
      "|    value_loss           | 1.02e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 675          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 169984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013391274 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.628       |\n",
      "|    explained_variance   | 0.04416865   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.94e+05     |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.000823    |\n",
      "|    value_loss           | 9.49e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 665          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010279322 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.631       |\n",
      "|    explained_variance   | 0.048045218  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+05      |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.000141    |\n",
      "|    value_loss           | 4.13e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 657          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002045182 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.632       |\n",
      "|    explained_variance   | 0.048484027  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.33e+05     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.000689    |\n",
      "|    value_loss           | 1.2e+06      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 653           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 34            |\n",
      "|    total_timesteps      | 176128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024949314 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.623        |\n",
      "|    explained_variance   | 0.03607911    |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.39e+05      |\n",
      "|    n_updates            | 850           |\n",
      "|    policy_gradient_loss | -0.000324     |\n",
      "|    value_loss           | 6.94e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 648          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011751635 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.633       |\n",
      "|    explained_variance   | -0.041229963 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.67e+05     |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    value_loss           | 7.43e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 646           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 41            |\n",
      "|    total_timesteps      | 180224        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034189475 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.624        |\n",
      "|    explained_variance   | 0.055882335   |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.69e+05      |\n",
      "|    n_updates            | 870           |\n",
      "|    policy_gradient_loss | -2.25e-05     |\n",
      "|    value_loss           | 9.38e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.37572e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | 0.047530115 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.64e+05    |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.000174   |\n",
      "|    value_loss           | 1.46e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.62449e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.0899418   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.13e+05    |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.000171   |\n",
      "|    value_loss           | 9.43e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 649           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 50            |\n",
      "|    total_timesteps      | 186368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7417805e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.61         |\n",
      "|    explained_variance   | 0.058482945   |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.19e+05      |\n",
      "|    n_updates            | 900           |\n",
      "|    policy_gradient_loss | -0.000137     |\n",
      "|    value_loss           | 1.08e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 651          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.408271e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.612       |\n",
      "|    explained_variance   | 0.06747526   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.22e+05     |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -4.63e-05    |\n",
      "|    value_loss           | 7.29e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 652           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 56            |\n",
      "|    total_timesteps      | 190464        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017067316 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.602        |\n",
      "|    explained_variance   | -0.0070734024 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.94e+05      |\n",
      "|    n_updates            | 920           |\n",
      "|    policy_gradient_loss | -0.000427     |\n",
      "|    value_loss           | 9.74e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 654           |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 59            |\n",
      "|    total_timesteps      | 192512        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8930815e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.593        |\n",
      "|    explained_variance   | 0.03278148    |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.27e+05      |\n",
      "|    n_updates            | 930           |\n",
      "|    policy_gradient_loss | -7.31e-05     |\n",
      "|    value_loss           | 4.38e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 655           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 62            |\n",
      "|    total_timesteps      | 194560        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.3179177e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.588        |\n",
      "|    explained_variance   | 0.103859365   |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.13e+05      |\n",
      "|    n_updates            | 940           |\n",
      "|    policy_gradient_loss | -4.93e-05     |\n",
      "|    value_loss           | 7e+05         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 656          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005221497 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.577       |\n",
      "|    explained_variance   | 0.05776161   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+05     |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.000237    |\n",
      "|    value_loss           | 5.05e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 658           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 68            |\n",
      "|    total_timesteps      | 198656        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3459503e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.564        |\n",
      "|    explained_variance   | -0.05108142   |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.11e+05      |\n",
      "|    n_updates            | 960           |\n",
      "|    policy_gradient_loss | -0.000137     |\n",
      "|    value_loss           | 5.73e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 656           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 71            |\n",
      "|    total_timesteps      | 200704        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028192974 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.553        |\n",
      "|    explained_variance   | 0.047953963   |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.14e+05      |\n",
      "|    n_updates            | 970           |\n",
      "|    policy_gradient_loss | -0.000777     |\n",
      "|    value_loss           | 6.74e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 652          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.441404e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | -0.013862729 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.07e+05     |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -2.74e-05    |\n",
      "|    value_loss           | 7.04e+05     |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Schritt 1: Daten laden und vorbereiten\n",
    "# Hier werden die historischen Bitcoin-Daten geladen und technische Indikatoren hinzugefügt.\n",
    "data = fetch_bitcoin_data('2018-01-01', '2023-12-31')  # Daten von 2018 bis Ende 2023\n",
    "data = add_technical_indicators(data)  # Füge technische Indikatoren wie gleitende Durchschnitte hinzu\n",
    "if data.empty:\n",
    "    raise ValueError(\"Die geladenen Daten sind leer. Überprüfen Sie den Zeitraum oder die API.\")\n",
    "\n",
    "# Schritt 2: Umgebung initialisieren\n",
    "# Die Umgebung simuliert den Bitcoin-Handel, basierend auf den vorbereiteten Daten.\n",
    "env = DummyVecEnv([lambda: BitcoinTradingEnv(data, window_size=60)])  # 60-Tage-Fenster\n",
    "\n",
    "# Schritt 3: Modell laden oder neu erstellen\n",
    "# Hier wird versucht, ein bereits gespeichertes Modell zu laden.\n",
    "# Falls keins existiert, wird ein neues Modell erstellt.\n",
    "try:\n",
    "    model = PPO.load(\"bitcoin_trading_model.zip\", env=env)  # Versuche, ein bestehendes Modell zu laden\n",
    "    print(\"Modell erfolgreich geladen. Training wird fortgesetzt.\")\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(f\"Kein bestehendes Modell gefunden oder Fehler beim Laden: {e}\")\n",
    "    model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=\"./bitcoin_trading_logs/\")  # Neues Modell erstellen\n",
    "\n",
    "# Schritt 4: Training des Modells\n",
    "# Das Modell wird für eine bestimmte Anzahl von Schritten trainiert. Es beginnt dort, wo es zuletzt aufgehört hat.\n",
    "total_timesteps = 50000  # Anzahl der Trainingsschritte\n",
    "model.learn(total_timesteps=total_timesteps, reset_num_timesteps=False)  # Fortlaufendes Training\n",
    "print(f\"Modell wurde für {total_timesteps} Schritte trainiert.\")\n",
    "\n",
    "# Schritt 5: Evaluierung des Modells\n",
    "mean_reward, std_reward = evaluate_trading_model(model, env)\n",
    "\n",
    "# Schritt 6: Modell speichern\n",
    "# Das Modell wird immer gespeichert, um sicherzustellen, dass Fortschritte nicht verloren gehen.\n",
    "model.save(\"bitcoin_trading_model.zip\")\n",
    "print(\"Modell wurde gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Lade die neuesten Daten (z. B. bis 31.12.2023)\n",
    "future_data = fetch_bitcoin_data('2023-01-01', '2023-12-31')  # Daten bis Ende 2023\n",
    "future_data = add_technical_indicators(future_data)\n",
    "\n",
    "# Nutze die letzten 60 Tage als Startpunkt\n",
    "recent_data = future_data[-60:]  # Hole die letzten 60 Tage\n",
    "\n",
    "# 2. Initialisiere die Umgebung mit den neuesten Daten\n",
    "env = DummyVecEnv([lambda: BitcoinTradingEnv(future_data, window_size=60)])\n",
    "\n",
    "# 3. Vorhersage für 30 Tage simulieren\n",
    "observations = recent_data[['open', 'high', 'low', 'close', 'volume']].values[-60:]  # Initiales Fenster\n",
    "predicted_actions = []\n",
    "\n",
    "for day in range(30):  # Simuliere 30 Tage\n",
    "    # Modell macht eine Vorhersage basierend auf den aktuellen Beobachtungen\n",
    "    action, _ = model.predict(observations, deterministic=True)\n",
    "    predicted_actions.append(action)\n",
    "\n",
    "    # Optional: Simuliere den Effekt der Aktion oder aktualisiere die Beobachtungen\n",
    "    # Für echte Prognosen müssten Sie hier die Kursbewegung schätzen oder weitere Daten einfügen.\n",
    "\n",
    "# 4. Ergebnisse auswerten\n",
    "print(\"Vorhergesagte Aktionen für die nächsten 30 Tage:\", predicted_actions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
