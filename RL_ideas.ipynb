{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation und Einrichtung\n",
    "Bevor du startest, stelle sicher, dass du die folgenden Pakete installiert hast. Führe in einer Jupyter-Notebook-Zelle Folgendes aus:\n",
    "\n",
    "``pip install stable-baselines3 pandas matplotlib``\n",
    "\n",
    "stable-baselines3: Für Reinforcement Learning.\n",
    "pandas: Für die Datenverarbeitung.\n",
    "matplotlib: Für die grafische Darstellung.\n",
    "ccxt: Für die API-Anbindung an Kryptobörsen wie Binance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Datenimport und Vorbereitung\n",
    "In dieser Zelle holen wir die historischen Bitcoin-Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "def fetch_bitcoin_data(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Ruft Bitcoin-Daten von Yahoo Finance für den angegebenen Zeitraum ab.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): Startdatum im Format 'YYYY-MM-DD'.\n",
    "        end_date (str): Enddatum im Format 'YYYY-MM-DD'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame mit den historischen Kursdaten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Überprüfung der Datumsformate\n",
    "        pd.to_datetime(start_date)\n",
    "        pd.to_datetime(end_date)\n",
    "\n",
    "        # Sicherstellen, dass start_date vor end_date liegt\n",
    "        if start_date >= end_date:\n",
    "            raise ValueError(\"Das Startdatum muss vor dem Enddatum liegen.\")\n",
    "\n",
    "        # Lade Daten von Yahoo Finance\n",
    "        df = yf.download(\"BTC-USD\", start=start_date, end=end_date, interval=\"1d\")\n",
    "\n",
    "        # Überprüfen, ob Daten zurückgegeben wurden\n",
    "        if df.empty:\n",
    "            raise ValueError(\"Keine Daten für den angegebenen Zeitraum verfügbar.\")\n",
    "\n",
    "        # Umbenennen der Spalten für Konsistenz\n",
    "        df.rename(columns={\n",
    "            \"Open\": \"open\",\n",
    "            \"High\": \"high\",\n",
    "            \"Low\": \"low\",\n",
    "            \"Close\": \"close\",\n",
    "            \"Volume\": \"volume\"\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Filtere die relevanten Spalten und setze den Zeitstempel als Index\n",
    "        df = df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "        df.index.name = \"timestamp\"\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Abrufen der Daten: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price               open          high           low         close  \\\n",
      "Ticker           BTC-USD       BTC-USD       BTC-USD       BTC-USD   \n",
      "timestamp                                                            \n",
      "2018-01-01  14112.200195  14112.200195  13154.700195  13657.200195   \n",
      "2018-01-02  13625.000000  15444.599609  13163.599609  14982.099609   \n",
      "2018-01-03  14978.200195  15572.799805  14844.500000  15201.000000   \n",
      "2018-01-04  15270.700195  15739.700195  14522.200195  15599.200195   \n",
      "2018-01-05  15477.200195  17705.199219  15202.799805  17429.500000   \n",
      "\n",
      "Price            volume  \n",
      "Ticker          BTC-USD  \n",
      "timestamp                \n",
      "2018-01-01  10291200000  \n",
      "2018-01-02  16846600192  \n",
      "2018-01-03  16871900160  \n",
      "2018-01-04  21783199744  \n",
      "2018-01-05  23840899072  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Abrufen der Daten\n",
    "data = fetch_bitcoin_data('2018-01-01', '2023-12-01')\n",
    "print(data.head())  # Zeige die ersten Zeilen der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **fetch_ohlcv**: Ruft Open, High, Low, Close, Volume (OHLCV) Daten ab.\n",
    "- **timestamp**: Zeitstempel für jeden Tag.\n",
    "- **close**: Schlusskurs, der für das Training verwendet wird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umgebung und Agent erstellen\n",
    "Hier definieren wir die RL-Umgebung und den Agenten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "class BitcoinTradingEnv(gym.Env):\n",
    "    def __init__(self, data, window_size=30):\n",
    "        super(BitcoinTradingEnv, self).__init__()\n",
    "        self.data = data[['open', 'high', 'low', 'close', 'volume', 'sma_10', 'sma_30', 'ema_10', 'ema_30']].values\n",
    "        self.window_size = window_size\n",
    "        self.current_step = window_size\n",
    "\n",
    "        # Action Space: Kaufen, Verkaufen, Halten\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "\n",
    "        # Observation Space: Fenstergröße x Feature-Anzahl\n",
    "        n_features = self.data.shape[1]\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0, high=1, shape=(window_size, n_features), dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = self.window_size\n",
    "        return self._get_observation()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        Gibt ein Fenster der letzten `window_size` Tage für alle Features zurück.\n",
    "        \"\"\"\n",
    "        window = self.data[self.current_step - self.window_size:self.current_step]\n",
    "        normalized_window = (window - np.min(self.data, axis=0)) / (\n",
    "            np.max(self.data, axis=0) - np.min(self.data, axis=0)\n",
    "        )\n",
    "        return normalized_window\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Führt eine Aktion aus und berechnet die Belohnung.\n",
    "        \"\"\"\n",
    "        reward = 0  # Default-Belohnung\n",
    "\n",
    "        # Abbruchbedingung bei Überschreiten der Datenlänge\n",
    "        if self.current_step >= len(self.data) - 2:\n",
    "            done = True\n",
    "            return self._get_observation(), reward, done, {}\n",
    "\n",
    "        price_now = self.data[self.current_step, 3]  # Schließen-Preis heute\n",
    "        price_next = self.data[self.current_step + 1, 3]  # Schließen-Preis morgen\n",
    "\n",
    "        # Aktion auswerten\n",
    "        if action == 1:  # Kaufen\n",
    "            reward = (price_next - price_now) - 0.001 * price_now  # Handelskosten\n",
    "        elif action == 2:  # Verkaufen\n",
    "            reward = (price_now - price_next) - 0.001 * price_now  # Handelskosten\n",
    "        elif action == 0:  # Halten\n",
    "            reward = -0.01  # Minimaler Verlust für Inaktivität\n",
    "\n",
    "        # Nächster Schritt\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Teste die Beobachtung\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBeobachtung nach Reset:\u001b[39m\u001b[38;5;124m\"\u001b[39m, obs\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Sollte (1, 60) sein, da `DummyVecEnv` die Dimension erweitert\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "# Teste die Beobachtung\n",
    "env = DummyVecEnv([lambda: BitcoinTradingEnv(data, window_size=60)])  # 60-Tage-Fenster\n",
    "obs = env.reset()\n",
    "print(\"Beobachtung nach Reset:\", obs.shape)  # Sollte (1, 60) sein, da `DummyVecEnv` die Dimension erweitert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(data):\n",
    "    \"\"\"\n",
    "    Fügt technische Indikatoren wie gleitende Durchschnitte dem DataFrame hinzu.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Historische Kursdaten.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame mit zusätzlichen Indikatoren.\n",
    "    \"\"\"\n",
    "    data['sma_10'] = data['close'].rolling(window=10).mean()\n",
    "    data['sma_30'] = data['close'].rolling(window=30).mean()\n",
    "    data['ema_10'] = data['close'].ewm(span=10, adjust=False).mean()\n",
    "    data['ema_30'] = data['close'].ewm(span=30, adjust=False).mean()\n",
    "    \n",
    "    # Entferne NaN-Werte, die durch gleitende Fenster entstehen\n",
    "    data = data.dropna()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training und Modell speichern\n",
    "Führe diesen Code aus, um das Modell zu trainieren und zu speichern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_trading_model(model, env, n_eval_episodes=10):\n",
    "    \"\"\"\n",
    "    Evaluiert die Leistung des Modells über eine bestimmte Anzahl von Episoden.\n",
    "\n",
    "    # Args:\n",
    "        model: Das trainierte RL-Modell.\n",
    "        env: Die Handelsumgebung.\n",
    "        n_eval_episodes (int): Anzahl der Episoden zur Evaluierung.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Durchschnittliche Belohnung und Standardabweichung.\n",
    "    \"\"\"\n",
    "    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=n_eval_episodes, deterministic=True)\n",
    "    print(f\"Durchschnittliche Belohnung: {mean_reward} ± {std_reward}\")\n",
    "    return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\tlfin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modell erfolgreich geladen. Training wird fortgesetzt.\n",
      "Logging to ./bitcoin_trading_logs/PPO_0\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1102   |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 1      |\n",
      "|    total_timesteps | 206848 |\n",
      "-------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 719           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 5             |\n",
      "|    total_timesteps      | 208896        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4673278e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.569        |\n",
      "|    explained_variance   | 0.065001905   |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.55e+05      |\n",
      "|    n_updates            | 1010          |\n",
      "|    policy_gradient_loss | -7.18e-06     |\n",
      "|    value_loss           | 4.79e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 637           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 210944        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.0203234e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.569        |\n",
      "|    explained_variance   | 0.03544104    |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.36e+05      |\n",
      "|    n_updates            | 1020          |\n",
      "|    policy_gradient_loss | -2.31e-05     |\n",
      "|    value_loss           | 5.69e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 597           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 13            |\n",
      "|    total_timesteps      | 212992        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4556928e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.568        |\n",
      "|    explained_variance   | -0.060851574  |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.42e+05      |\n",
      "|    n_updates            | 1030          |\n",
      "|    policy_gradient_loss | -0.000108     |\n",
      "|    value_loss           | 4.41e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 580           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 215040        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2284832e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.566        |\n",
      "|    explained_variance   | 0.042880237   |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.65e+05      |\n",
      "|    n_updates            | 1040          |\n",
      "|    policy_gradient_loss | -0.00015      |\n",
      "|    value_loss           | 5.53e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 581           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 217088        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0894029e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.57         |\n",
      "|    explained_variance   | 0.09137261    |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.32e+05      |\n",
      "|    n_updates            | 1050          |\n",
      "|    policy_gradient_loss | -4.95e-05     |\n",
      "|    value_loss           | 4.17e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 563           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 219136        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046342905 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.561        |\n",
      "|    explained_variance   | 0.0051221848  |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.96e+05      |\n",
      "|    n_updates            | 1060          |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    value_loss           | 8.07e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 572           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 28            |\n",
      "|    total_timesteps      | 221184        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013020253 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.541        |\n",
      "|    explained_variance   | -0.07724488   |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.5e+05       |\n",
      "|    n_updates            | 1070          |\n",
      "|    policy_gradient_loss | -0.000351     |\n",
      "|    value_loss           | 3.65e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 578           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 31            |\n",
      "|    total_timesteps      | 223232        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2953878e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.533        |\n",
      "|    explained_variance   | 0.012933016   |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.21e+05      |\n",
      "|    n_updates            | 1080          |\n",
      "|    policy_gradient_loss | -0.000183     |\n",
      "|    value_loss           | 3.5e+05       |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Schritt 1: Daten laden und vorbereiten\n",
    "# Hier werden die historischen Bitcoin-Daten geladen und technische Indikatoren hinzugefügt.\n",
    "data = fetch_bitcoin_data('2018-01-01', '2023-12-31')  # Daten von 2018 bis Ende 2023\n",
    "data = add_technical_indicators(data)  # Füge technische Indikatoren wie gleitende Durchschnitte hinzu\n",
    "if data.empty:\n",
    "    raise ValueError(\"Die geladenen Daten sind leer. Überprüfen Sie den Zeitraum oder die API.\")\n",
    "\n",
    "# Schritt 2: Umgebung initialisieren\n",
    "# Die Umgebung simuliert den Bitcoin-Handel, basierend auf den vorbereiteten Daten.\n",
    "env = DummyVecEnv([lambda: BitcoinTradingEnv(data, window_size=60)])  # 60-Tage-Fenster\n",
    "\n",
    "# Schritt 3: Modell laden oder neu erstellen\n",
    "# Hier wird versucht, ein bereits gespeichertes Modell zu laden.\n",
    "# Falls keins existiert, wird ein neues Modell erstellt.\n",
    "try:\n",
    "    model = PPO.load(\"bitcoin_trading_model.zip\", env=env)  # Versuche, ein bestehendes Modell zu laden\n",
    "    print(\"Modell erfolgreich geladen. Training wird fortgesetzt.\")\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(f\"Kein bestehendes Modell gefunden oder Fehler beim Laden: {e}\")\n",
    "    model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=\"./bitcoin_trading_logs/\")  # Neues Modell erstellen\n",
    "\n",
    "# Schritt 4: Training des Modells\n",
    "# Das Modell wird für eine bestimmte Anzahl von Schritten trainiert. Es beginnt dort, wo es zuletzt aufgehört hat.\n",
    "total_timesteps = 50000  # Anzahl der Trainingsschritte\n",
    "model.learn(total_timesteps=total_timesteps, reset_num_timesteps=False)  # Fortlaufendes Training\n",
    "print(f\"Modell wurde für {total_timesteps} Schritte trainiert.\")\n",
    "\n",
    "# Schritt 5: Evaluierung des Modells\n",
    "mean_reward, std_reward = evaluate_trading_model(model, env)\n",
    "\n",
    "# Schritt 6: Modell speichern\n",
    "# Das Modell wird immer gespeichert, um sicherzustellen, dass Fortschritte nicht verloren gehen.\n",
    "model.save(\"bitcoin_trading_model.zip\")\n",
    "print(\"Modell wurde gespeichert.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
